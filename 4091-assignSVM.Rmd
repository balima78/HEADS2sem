## Assignment SVM

2020-05-12

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

Read data and packages
```{r}
library(caret)
library(pROC)
# Get data set from UCI repository - Breast Cancer Coimbra
# - available from https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra

# Define the filename
filename <- "2.UploadedData/dataR2.csv"

# Load the CSV file from the local directory
dataset <- read.csv(filename, header=T)

# Define Classification as factor
dataset$Classification <- factor(dataset$Classification, levels=1:2, labels=c("Control", "Patient"))
```

Holdout a validation set, by defining the indices of the training set
```{r}
set.seed(523)
training.index <- createDataPartition(dataset$Classification, p=0.8, list=FALSE)
validation <- dataset[-training.index,]
dataset <- dataset[training.index,]
```

Levels of the class
```{r}
levels(dataset$Classification)
```

Class distribution
```{r}
proportions <- prop.table(table(dataset$Classification))
cbind(Frequency=table(dataset$Classification), Proportion=round(proportions*100,2))
```

Statistical Summary
```{r}
summary(dataset)
```

Learn SVM with radial kernel (all features)
```{r}
# Load package 'e1071'
library("e1071")

svm.all <- svm(Classification ~ ., data=dataset)
```

Summary
```{r}
summary(svm.all)
```

classification plot for Glucose and Age
```{r}
plot(svm.all, 
     data = dataset,
     Glucose ~ Age, # para ver em 2D é necessário selecionar duas variaveis
     svSymbol = 17, 
     dataSymbol = 20, 
     symbolPalette = c(2,3),
     color.palette=grey.colors,
     slice = list(
       #                  Age = 59.01,
       BMI = 27.95, # as restantes variaveis são fixadas para os seus valores médios
       #                  Glucose=98.65,
       Insulin=10.623, # mean value
       HOMA=2.9147, # mean value
       Leptin=27.994, # mean value
       Adiponectin=10.153, # mean value
       Resistin=15.13, # mean value
       MCP.1=554.98)) # mean value
```

Run algorithms using 3 times 10-fold cross validation
```{r}
metric <- "ROC"
control <- trainControl(method="repeatedcv", number=10,
                        summaryFunction=twoClassSummary, 
                        classProbs=T,
                        savePredictions = T, repeats = 3)

set.seed(7)
fit.svm.linear <- train(Classification ~ ., data=dataset, 
                        method="svmLinear", 
                        metric=metric, 
                        trControl=control, 
                        preProcess = c("center", "scale"), 
                        tuneLength = 10)
set.seed(7)
fit.svm.radial <- train(Classification ~ ., data=dataset, 
                        method="svmRadial", 
                        metric=metric, 
                        trControl=control, 
                        preProcess = c("center", "scale"), 
                        tuneLength = 10)

```

Summarize accuracy of models
```{r}
fit.models <- list(linear=fit.svm.linear, radial=fit.svm.radial)
results <- resamples(fit.models)
summary(results)
```

ROC curves for models
```{r}
par(mfrow=c(1,2))

rocs <- lapply(fit.models, function(fit){plot.roc(fit$pred$obs,fit$pred$Patient,
                                                  main=paste("3 x 10-fold CV -",fit$method), 
                                                  debug=F, print.auc=T)})
```

Compare accuracy of models
```{r}
dotplot(results)
```

Inspect model linear
```{r}
print(fit.svm.linear)
getModelInfo(fit.svm.linear)$svmLinear$parameters
```

Inspect model radial
```{r}
print(fit.svm.radial)
getModelInfo(fit.svm.radial)$svmRadial$parameters
```

ROC complexity for models
```{r}
plot(fit.svm.radial)
```

Improve Radial
```{r}
myGrid <- expand.grid(C = c(1,2,4,8), sigma=0.09382649)

set.seed(7)
fit.svm.radial.tune <- train(Classification ~ ., data=dataset, 
                             method="svmRadial", 
                             metric=metric, 
                             trControl=control,
                             tuneGrid = myGrid)

# ROC complexity for models
print(fit.svm.radial.tune)
```


Summarize accuracy of models
```{r}
fit.models <- list(linear=fit.svm.linear, 
                   radial=fit.svm.radial, 
                   tune=fit.svm.radial.tune)
results <- resamples(fit.models)
summary(results)
```

ROC curves for models
```{r}
par(mfrow=c(1,3))
rocs <- lapply(fit.models, function(fit){plot.roc(fit$pred$obs,fit$pred$Patient,
                                                  main=paste("3 x 10-fold CV -",fit$method), 
                                                  debug=F, 
                                                  print.auc=T)})
```

Compare accuracy of models
```{r}
dotplot(results)
```

Make predictions
```{r}
par(mfrow=c(1,1))

# Estimate skill of RF on the validation dataset
predictions.prob <- predict(fit.svm.radial.tune, validation, type="prob")
predictions <- predict(fit.svm.radial.tune, validation, type="raw")
confusionMatrix(predictions, validation$Classification)
```

plot ROC
```{r}
plot.roc(validation$Classification, 
         predictions.prob$Patient, 
         print.auc=T, 
         axes=F, 
         main=paste("3 x 10-fold CV -",fit.svm.radial.tune$method), 
         debug=F)
axis(1)
axis(2)
```

<img src="images/logoFMUP.png" alt="logotipo FMUP" style="width:100px;height:40px;" align="right">