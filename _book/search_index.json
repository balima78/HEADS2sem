[
["lesson-7.html", "4.9 Lesson 7", " 4.9 Lesson 7 2020-04-21 Machine Learning from Data Streams 4.9.1 Repositories R packages for machine learning in data streams Python/R connectable software for machine learning in data streams 4.9.2 Prequential evaluation method presented in Gama, Sebastiao &amp; Rodrigues (2013) Evaluation of Online Learning Algorithms and Concept Drift Detection pseudocodes on the article to R: 4.9.2.1 Update prequential Error estimator itera &lt;- 2000 Pe&lt;-NULL plot(NULL,xlab = &quot;examples&quot;, ylab = &quot;Prequential error&quot;, xlim = c(0,itera), ylim = c(-1,1), main = &quot;Algorithm 1: Prequential Error Estimator&quot;) for (i in 2:itera){ ## Loss at example i ## ei &lt;- ifelse(i&lt;=1000, rbinom(1, 1,.3), rbinom(1, 1,.8)) Pe[1]&lt;-0 Pe[i]&lt;-(ei + (i-1)*Pe[i-1]) / i points(x=i,y=Pe[i],pch=20,cex=.1,col=&quot;black&quot;) } 4.9.2.2 Update Prequential Error Estimator in sliding window w&lt;-50 itera &lt;- 2000 Pw&lt;-NULL E&lt;-NULL plot(NULL,xlab = &quot;examples&quot;, ylab = &quot;Prequential error&quot;, xlim = c(0,itera), ylim = c(-1,1), main = &quot;Algorithm 2: sliding window&quot;) for (i in 1:itera){ ## Loss at example i ## ei &lt;- ifelse(i&lt;=1000, rbinom(1, 1,.3), rbinom(1, 1,.8)) S&lt;-0 E[1:w]&lt;-0 p&lt;-((i-1) %% w) + 1 S&lt;-S - E[p] + ei Pw[i]=S/min(w,i) points(x=i,y=Pw[i],pch=20,cex=.1,col=&quot;black&quot;) } 4.9.2.3 Update rule for Prequential error estimator using fading factors a &lt;- 0.999 itera &lt;- 2000 Pa&lt;-NULL Sa&lt;-NULL Na&lt;-NULL plot(NULL,xlab = &quot;examples&quot;, ylab = &quot;Prequential error&quot;, xlim = c(0,itera), ylim = c(-1,1), main = &quot;Algorithm 3: using fading factors&quot;) for (i in 2:itera){ ## Loss at example i ## ei &lt;- ifelse(i&lt;=1000, rbinom(1, 1,.3), rbinom(1, 1,.8)) Sa[1]&lt;-0 Na[1]&lt;-0 Pa[1]&lt;-0 Sa[i]&lt;-ei + a*Sa[i-1] Na[i]&lt;-1 + a*Na[i-1] Pa[i]&lt;-Sa[i]/Na[i] points(x=i,y=Pa[i],pch=20,cex=.1,col=&quot;black&quot;) } 4.9.2.4 Drift detector based on the ratio of two fading factors # required values itera&lt;- 2000 a1&lt;-0.999 a2&lt;-0.9 g&lt;-0.1 l&lt;-10 drift&lt;-logical() # Initialize the error estimators Sa1&lt;-NULL Na1&lt;-NULL Sa2&lt;-NULL Na2&lt;-NULL SR&lt;-NULL mT&lt;-NULL MT&lt;-NULL R&lt;-NULL plot(NULL,xlab = &quot;examples&quot;, ylab = &quot;Drift&quot;, xlim = c(0,itera), ylim = c(-1,1), main = &quot;Algorithm 4: Drift detector&quot;) for (i in 2:itera){ ## Loss at example i ## ei &lt;- ifelse(i&lt;=1000, rbinom(1, 1,.3), rbinom(1, 1,.8)) R[1]&lt;-0 Sa1[1]&lt;-1 Sa1[i]&lt;-ei + a1*Sa1[i-1] Na1[1]&lt;-0 Na1[i]&lt;-1+a1*Na1[i-1] Ma1&lt;-Sa1[i]/Na1[i] Sa2[1]&lt;-0 Sa2[i]&lt;-ei + a2*Sa2[i-1] Na2[1]&lt;-0 Na2[i]&lt;-1+a2*Na2[i-1] Ma2&lt;-Sa2[i]/Na2[i] R[i]&lt;-Ma2/Ma1 ## PH test ## SR[1]&lt;-0 SR[i]&lt;-SR[i-1] + R[i] mT[1]&lt;-0 mT[i]&lt;-mT[i-1] + R[i] - SR[i]/i - g MT&lt;-min(c(MT,mT[i])) if(mT[i]-MT &gt;= l) {drift = TRUE} else {drift = FALSE} points(x=i,y=drift,pch=20,cex=.1,col=&quot;black&quot;) } "]
]
